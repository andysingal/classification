{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bece1c7-b2b0-4a9d-846a-9f0c11517c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "! pip install -q pytorch-lightning\n",
    "! pip install -q bs4\n",
    "! pip install -q transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f82b7822-e332-473d-b87c-98ef4ea3e230",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install matplotlib pylab\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83bf2a78-091f-4162-a834-b6fcfc9fb3a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fdacab61cb0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import all libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from os import listdir\n",
    "\n",
    "# Huggingface transformers\n",
    "import transformers\n",
    "from transformers import BertModel,BertTokenizer,AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "import torch\n",
    "from torch import nn ,cuda\n",
    "from torch.utils.data import DataLoader,Dataset,RandomSampler, SequentialSampler\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "#handling html data\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "%matplotlib inline\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b9c8990-9b77-47c0-8061-1280ddc5dc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_csv_filenames( path_to_dir, suffix=\".csv\" ):\n",
    "    filenames = listdir(path_to_dir)\n",
    "    return [ filename for filename in filenames if filename.endswith( suffix ) ]\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bbab0446-75ff-40ef-9975-475584dac44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answers.csv\n",
      "Tags.csv\n",
      "Questions.csv\n"
     ]
    }
   ],
   "source": [
    "filenames = find_csv_filenames(\"csv_files\")\n",
    "for name in filenames:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5c94035-2619-40be-9d33-4a5a2e38e769",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_questions = pd.read_csv('csv_files/Questions.csv',encoding='latin-1')\n",
    "df_tags = pd.read_csv('csv_files/Tags.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de762cab-2818-4bf4-8e90-076de5ec7169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>OwnerUserId</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>Score</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2010-07-19T19:14:44Z</td>\n",
       "      <td>272</td>\n",
       "      <td>The Two Cultures: statistics vs. machine learn...</td>\n",
       "      <td>&lt;p&gt;Last year, I read a blog post from &lt;a href=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>59.0</td>\n",
       "      <td>2010-07-19T19:24:36Z</td>\n",
       "      <td>4</td>\n",
       "      <td>Forecasting demographic census</td>\n",
       "      <td>&lt;p&gt;What are some of the ways to forecast demog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>66.0</td>\n",
       "      <td>2010-07-19T19:25:39Z</td>\n",
       "      <td>208</td>\n",
       "      <td>Bayesian and frequentist reasoning in plain En...</td>\n",
       "      <td>&lt;p&gt;How would you describe in plain English the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2010-07-19T19:28:44Z</td>\n",
       "      <td>138</td>\n",
       "      <td>What is the meaning of p values and t values i...</td>\n",
       "      <td>&lt;p&gt;After taking a statistics course and then t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2010-07-19T19:31:47Z</td>\n",
       "      <td>58</td>\n",
       "      <td>Examples for teaching: Correlation does not me...</td>\n",
       "      <td>&lt;p&gt;There is an old saying: \"Correlation does n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  OwnerUserId          CreationDate  Score  \\\n",
       "0   6          5.0  2010-07-19T19:14:44Z    272   \n",
       "1  21         59.0  2010-07-19T19:24:36Z      4   \n",
       "2  22         66.0  2010-07-19T19:25:39Z    208   \n",
       "3  31         13.0  2010-07-19T19:28:44Z    138   \n",
       "4  36          8.0  2010-07-19T19:31:47Z     58   \n",
       "\n",
       "                                               Title  \\\n",
       "0  The Two Cultures: statistics vs. machine learn...   \n",
       "1                     Forecasting demographic census   \n",
       "2  Bayesian and frequentist reasoning in plain En...   \n",
       "3  What is the meaning of p values and t values i...   \n",
       "4  Examples for teaching: Correlation does not me...   \n",
       "\n",
       "                                                Body  \n",
       "0  <p>Last year, I read a blog post from <a href=...  \n",
       "1  <p>What are some of the ways to forecast demog...  \n",
       "2  <p>How would you describe in plain English the...  \n",
       "3  <p>After taking a statistics course and then t...  \n",
       "4  <p>There is an old saying: \"Correlation does n...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_questions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48829882-3bbe-456e-8623-5e4272c37115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>bayesian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>prior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>elicitation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>distributions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>normality</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id            Tag\n",
       "0   1       bayesian\n",
       "1   1          prior\n",
       "2   1    elicitation\n",
       "3   2  distributions\n",
       "4   2      normality"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tags.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad23742f-88ce-4d01-b099-5e25f4842113",
   "metadata": {},
   "source": [
    "# Pre-process the data\n",
    "The Body column contains data in a HTML format and thus we need to strip off the HTML also we will do a lower case conversion to reduce vocabulary size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36e060c4-3581-4ade-910a-f7b47adf2c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(text):\n",
    "\n",
    "    text = BeautifulSoup(text).get_text()\n",
    "  \n",
    "    # fetch alphabetic characters\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "\n",
    "    # convert text to lower case\n",
    "    text = text.lower()\n",
    "\n",
    "    # split text into tokens to remove whitespaces\n",
    "    tokens = text.split()\n",
    "\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0117a8e1-d20d-4da7-9a55-05f47c515477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the text in Body column\n",
    "df_questions['Clean_Body'] = df_questions['Body'].apply(pre_process)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "faa7f25e-036f-4b69-aae8-3de8eb3d6c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "r                     13236\n",
       "regression            10959\n",
       "machine-learning       6089\n",
       "time-series            5559\n",
       "probability            4217\n",
       "hypothesis-testing     3869\n",
       "self-study             3732\n",
       "distributions          3501\n",
       "logistic               3316\n",
       "classification         2881\n",
       "Name: Tag, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tags['Tag'].value_counts()[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6448e6a-927b-4a44-9b3f-2a0d900275c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove \"-\" from the tags\n",
    "df_tags['Tag']= df_tags['Tag'].apply(lambda x:re.sub(\"-\",\" \",x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a876d87e-1be8-4216-9f9b-e4457210537d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['r', 'regression', 'machine learning', 'time series', 'probability',\n",
       "       'hypothesis testing', 'self study', 'distributions', 'logistic',\n",
       "       'classification'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Consider only Top 10 tags - want to keep a smaller dataset\n",
    "top_tags = df_tags['Tag'].value_counts().keys()[0:10]\n",
    "top_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f4dc3f6-dba4-4e43-9ed5-0019e34ee590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[bayesian, prior, elicitation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[distributions, normality]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[software, open source]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[distributions, statistical significance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>[machine learning]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                       tags\n",
       "0   1             [bayesian, prior, elicitation]\n",
       "1   2                 [distributions, normality]\n",
       "2   3                    [software, open source]\n",
       "3   4  [distributions, statistical significance]\n",
       "4   6                         [machine learning]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First group tags Id wise\n",
    "df_tags = df_tags.groupby('Id').apply(lambda x:x['Tag'].values).reset_index(name='tags')\n",
    "df_tags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "db17f273-363e-4a0c-9f5f-7d442b0e58bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge tags and questions datasets\n",
    "df = pd.merge(df_questions,df_tags,how='inner',on='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba8c2629-6c62-4509-852e-13a10b9c173c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clean_Body</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>last year i read a blog post from brendan o co...</td>\n",
       "      <td>[machine learning]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what are some of the ways to forecast demograp...</td>\n",
       "      <td>[forecasting, population, census]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how would you describe in plain english the ch...</td>\n",
       "      <td>[bayesian, frequentist]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>after taking a statistics course and then tryi...</td>\n",
       "      <td>[hypothesis testing, t test, p value, interpre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>there is an old saying correlation does not me...</td>\n",
       "      <td>[correlation, teaching]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Clean_Body  \\\n",
       "0  last year i read a blog post from brendan o co...   \n",
       "1  what are some of the ways to forecast demograp...   \n",
       "2  how would you describe in plain english the ch...   \n",
       "3  after taking a statistics course and then tryi...   \n",
       "4  there is an old saying correlation does not me...   \n",
       "\n",
       "                                                tags  \n",
       "0                                 [machine learning]  \n",
       "1                  [forecasting, population, census]  \n",
       "2                            [bayesian, frequentist]  \n",
       "3  [hypothesis testing, t test, p value, interpre...  \n",
       "4                            [correlation, teaching]  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retain only the columns we will use for training the model - Tags will be the label\n",
    "df = df[['Clean_Body','tags']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cbdc2289-57fe-42ef-b07d-792e1e0aab1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out records ( values in clean_body and tags) that have atleast one of the top tags\n",
    "\n",
    "x=[] # To store the filtered clean_body values\n",
    "y=[] # to store the corresponding tags\n",
    "# Convert to list data type\n",
    "lst_top_tags = list(top_tags)\n",
    "\n",
    "for i in range(len(df['tags'])):\n",
    "    temp=[]\n",
    "    for tag in df['tags'][i]:\n",
    "        if tag in lst_top_tags:\n",
    "            temp.append(tag)\n",
    "\n",
    "    if(len(temp)>0):\n",
    "        x.append(df['Clean_Body'][i])\n",
    "        y.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e0d83548-39a3-436c-9a24-f337a8d2a80e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44928"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of records that will be used for training and testing\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "71972f8b-5f80-424f-9be7-366cf5cf8536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44928, 10)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode the tags(labels) in a binary format in order to be used for training\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    " \n",
    "yt = mlb.fit_transform(y)\n",
    "yt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b52b63e0-f905-444e-b4ef-090743a5c053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1 0 0 0 0 0]\n",
      "[('machine learning',)]\n",
      "['classification' 'distributions' 'hypothesis testing' 'logistic'\n",
      " 'machine learning' 'probability' 'r' 'regression' 'self study'\n",
      " 'time series']\n"
     ]
    }
   ],
   "source": [
    "# Getting a sense of how the tags data looks like\n",
    "print(yt[0])\n",
    "print(mlb.inverse_transform(yt[0].reshape(1,-1)))\n",
    "print(mlb.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62581ad6-3645-4312-9cf1-86532aad566f",
   "metadata": {},
   "source": [
    "View the distribution of word count/question to decide the max length for Text that will be used for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7e91f589-4a2a-4edd-a0c5-0213376a49a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compute no. of words in each question\n",
    "questions = x\n",
    "word_cnt = [len(quest.split()) for quest in questions]\n",
    "# Plot the distribution\n",
    "plt.figure(figsize=[8,5])\n",
    "plt.hist(word_cnt, bins = 40)\n",
    "plt.xlabel('Word Count/Question')\n",
    "plt.ylabel('# of Occurences')\n",
    "plt.title(\"Frequency of Word Counts/sentence\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f3bb32-072f-46ed-8cba-7bd4fdf422b6",
   "metadata": {},
   "source": [
    "# Split the dataset into training ,validation and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5f00043d-6de4-4329-8548-ef26f9a924f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# First Split for Train and Test\n",
    "x_train,x_test,y_train,y_test = train_test_split(x, yt, test_size=0.1, random_state=RANDOM_SEED,shuffle=True)\n",
    "# Next split Train in to training and validation\n",
    "x_tr,x_val,y_tr,y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=RANDOM_SEED,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "27bdeee7-eb17-4c3d-ad9c-241d0260f81f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32348, 8087, 4493)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_tr) ,len(x_val), len(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f9ca1a-329b-44d2-8593-0639f6408e56",
   "metadata": {},
   "source": [
    "# Preparing the Dataset and DataModule\n",
    "First create QTagDataset class based on the Dataset class,that readies the text in a format needed for the BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2a426671-99b9-4d1b-b7f9-f5b0e2835d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QTagDataset(Dataset):\n",
    "    def __init__(self,quest,tags, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.text = quest\n",
    "        self.labels = tags\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "    \n",
    "    def __getitem__(self, item_idx):\n",
    "        text = self.text[item_idx]\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True, # Add [CLS] [SEP]\n",
    "            max_length= self.max_len,\n",
    "            padding = 'max_length',\n",
    "            return_token_type_ids= False,\n",
    "            return_attention_mask= True, # Differentiates padded vs normal token\n",
    "            truncation=True, # Truncate data beyond max length\n",
    "            return_tensors = 'pt' # PyTorch Tensor format\n",
    "          )\n",
    "        \n",
    "        input_ids = inputs['input_ids'].flatten()\n",
    "        attn_mask = inputs['attention_mask'].flatten()\n",
    "        #token_type_ids = inputs[\"token_type_ids\"]\n",
    "        \n",
    "        return {\n",
    "            'input_ids': input_ids ,\n",
    "            'attention_mask': attn_mask,\n",
    "            'label': torch.tensor(self.labels[item_idx], dtype=torch.float)\n",
    "            \n",
    "        }\n",
    "\n",
    "class QTagDataModule (pl.LightningDataModule):\n",
    "    \n",
    "    def __init__(self,x_tr,y_tr,x_val,y_val,x_test,y_test,tokenizer,batch_size=16,max_token_len=200):\n",
    "        super().__init__()\n",
    "        self.tr_text = x_tr\n",
    "        self.tr_label = y_tr\n",
    "        self.val_text = x_val\n",
    "        self.val_label = y_val\n",
    "        self.test_text = x_test\n",
    "        self.test_label = y_test\n",
    "        self.tokenizer = tokenizer\n",
    "        self.batch_size = batch_size\n",
    "        self.max_token_len = max_token_len\n",
    "\n",
    "    def setup(self,stage=None):\n",
    "        self.train_dataset = QTagDataset(quest=self.tr_text, tags=self.tr_label, tokenizer=self.tokenizer,max_len = self.max_token_len)\n",
    "        self.val_dataset  = QTagDataset(quest=self.val_text,tags=self.val_label,tokenizer=self.tokenizer,max_len = self.max_token_len)\n",
    "        self.test_dataset  = QTagDataset(quest=self.test_text,tags=self.test_label,tokenizer=self.tokenizer,max_len = self.max_token_len)\n",
    "        \n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader (self.train_dataset,batch_size = self.batch_size,shuffle = True , num_workers=2)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader (self.val_dataset,batch_size= 16)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader (self.test_dataset,batch_size= 16)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff63976-29c7-4963-86e8-8ae3312eece4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "162766c5-f470-46d7-836d-39f7d3376676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Bert tokenizer\n",
    "BERT_MODEL_NAME = \"bert-base-cased\" # we will use the BERT base model(the smaller one)\n",
    "Bert_tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "336f57ac-f2ca-48cd-ba82-ecdb4705106c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (601 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Question having word count > 300: is  7205\n"
     ]
    }
   ],
   "source": [
    "max_word_cnt = 300\n",
    "quest_cnt = 0\n",
    "\n",
    "# For every sentence...\n",
    "for question in questions:\n",
    "\n",
    "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
    "    input_ids = Bert_tokenizer.encode(question, add_special_tokens=True)\n",
    "\n",
    "    # Update the maximum sentence length.\n",
    "    if len(input_ids) > max_word_cnt:\n",
    "        quest_cnt +=1\n",
    "\n",
    "print(f'# Question having word count > {max_word_cnt}: is  {quest_cnt}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a817d685-55d6-4b1e-8427-c9ac19ba00f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the parameters that will be use for training\n",
    "N_EPOCHS = 12\n",
    "BATCH_SIZE = 32\n",
    "MAX_LEN = 300\n",
    "LR = 2e-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b9de1f79-84a7-4319-9f3a-2b4f7606f645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and set up the data_module\n",
    "QTdata_module = QTagDataModule(x_tr,y_tr,x_val,y_val,x_test,y_test,Bert_tokenizer,BATCH_SIZE,MAX_LEN)\n",
    "QTdata_module.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcae7e1e-3b60-4aa7-bd46-e4706547cb2d",
   "metadata": {},
   "source": [
    "# Train the Model\n",
    "Setup the Multi-label Classifier Model - dervived from LightningModule , similar to nn.module of PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7f616fd2-42b7-4c87-a696-aa13a6b70a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QTagClassifier(pl.LightningModule):\n",
    "    # Set up the classifier\n",
    "    def __init__(self, n_classes=10, steps_per_epoch=None, n_epochs=3, lr=2e-5 ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.bert = BertModel.from_pretrained(BERT_MODEL_NAME, return_dict=True)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size,n_classes) # outputs = number of labels\n",
    "        self.steps_per_epoch = steps_per_epoch\n",
    "        self.n_epochs = n_epochs\n",
    "        self.lr = lr\n",
    "        self.criterion = nn.BCEWithLogitsLoss()\n",
    "        \n",
    "    def forward(self,input_ids, attn_mask):\n",
    "        output = self.bert(input_ids = input_ids ,attention_mask = attn_mask)\n",
    "        output = self.classifier(output.pooler_output)\n",
    "                \n",
    "        return output\n",
    "    \n",
    "    \n",
    "    def training_step(self,batch,batch_idx):\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['label']\n",
    "        \n",
    "        outputs = self(input_ids,attention_mask)\n",
    "        loss = self.criterion(outputs,labels)\n",
    "        self.log('train_loss',loss , prog_bar=True,logger=True)\n",
    "        \n",
    "        return {\"loss\" :loss, \"predictions\":outputs, \"labels\": labels }\n",
    "\n",
    "\n",
    "    def validation_step(self,batch,batch_idx):\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['label']\n",
    "        \n",
    "        outputs = self(input_ids,attention_mask)\n",
    "        loss = self.criterion(outputs,labels)\n",
    "        self.log('val_loss',loss , prog_bar=True,logger=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def test_step(self,batch,batch_idx):\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['label']\n",
    "        \n",
    "        outputs = self(input_ids,attention_mask)\n",
    "        loss = self.criterion(outputs,labels)\n",
    "        self.log('test_loss',loss , prog_bar=True,logger=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.parameters() , lr=self.lr)\n",
    "        warmup_steps = self.steps_per_epoch//3\n",
    "        total_steps = self.steps_per_epoch * self.n_epochs - warmup_steps\n",
    "\n",
    "        scheduler = get_linear_schedule_with_warmup(optimizer,warmup_steps,total_steps)\n",
    "\n",
    "        return [optimizer], [scheduler]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cc7f58b3-236d-4fcb-8969-ecf56efc3fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the classifier model\n",
    "steps_per_epoch = len(x_tr)//BATCH_SIZE\n",
    "model = QTagClassifier(n_classes=10, steps_per_epoch=steps_per_epoch,n_epochs=N_EPOCHS,lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "75f8272a-c536-484b-be30-320ce9093e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize Pytorch Lightning callback for Model checkpointing\n",
    "\n",
    "# saves a file like: input/QTag-epoch=02-val_loss=0.32.ckpt\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',# monitored quantity\n",
    "    filename='QTag-{epoch:02d}-{val_loss:.2f}',\n",
    "    save_top_k=3, #  save the top 3 models\n",
    "    mode='min', # mode of the monitored quantity  for optimization\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "07760a05-5967-4a19-abed-783f099dbadb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ankush.singal/opt/anaconda3/envs/ml_env/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:97: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=30)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  f\"Setting `Trainer(progress_bar_refresh_rate={progress_bar_refresh_rate})` is deprecated in v1.5 and\"\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the Model Trainer\n",
    "trainer = pl.Trainer(max_epochs = N_EPOCHS , callbacks=[checkpoint_callback],progress_bar_refresh_rate = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "10f9eb1c-b9bf-483b-835a-1fbc16d28883",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing logger folder: /Users/ankush.singal/Desktop/Schneider-classification/lightning_logs\n",
      "/Users/ankush.singal/opt/anaconda3/envs/ml_env/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "\n",
      "  | Name       | Type              | Params\n",
      "-------------------------------------------------\n",
      "0 | bert       | BertModel         | 108 M \n",
      "1 | classifier | Linear            | 7.7 K \n",
      "2 | criterion  | BCEWithLogitsLoss | 0     \n",
      "-------------------------------------------------\n",
      "108 M     Trainable params\n",
      "0         Non-trainable params\n",
      "108 M     Total params\n",
      "433.272   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|                       | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ankush.singal/opt/anaconda3/envs/ml_env/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:245: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ankush.singal/opt/anaconda3/envs/ml_env/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:245: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|                                         | 0/1517 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ankush.singal/opt/anaconda3/envs/ml_env/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:726: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "# Train the Classifier Model\n",
    "trainer.fit(model, QTdata_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b5d5ec-b68d-4700-8182-e413cd18e61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model performance on the test dataset\n",
    "trainer.test(model,datamodule=QTdata_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c184d820-a499-449a-ac83-827fdcae43ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the logs using tensorboard.\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45af9dd7-616d-4c5a-af66-fe1acff0bea2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
